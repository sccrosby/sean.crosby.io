<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Classification on Sean C. Crosby</title>
    <link>https://sccrosby.github.io/tags/classification/</link>
    <description>Recent content in Classification on Sean C. Crosby</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 28 Dec 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://sccrosby.github.io/tags/classification/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Can we visualize decision space for different classifiers?</title>
      <link>https://sccrosby.github.io/post/post005/</link>
      <pubDate>Tue, 28 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://sccrosby.github.io/post/post005/</guid>
      <description>Support Vector Machines (SVM) are seemingly derived from a intuitive concept, drawing a decision boundary with the widest margin (aka gutter, street, etc.). While this only really applies to the linear problem in which the data are indeed separable, I find it particularly helpful in visualizing the decision space of the model. Unlike a random forest or multi-layer neural network, it is easy to picture model space. While not a novel idea in the slightest, this provoked me to consider decision space for several classification algorithms to hopefully gain insight into other techniques, and with this insight select appropriate methods for future questions.</description>
    </item>
    
  </channel>
</rss>
